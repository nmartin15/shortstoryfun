# Short Story Pipeline - Environment Configuration
# Copy this file to .env and fill in your values

# Flask Configuration
FLASK_ENV=development  # Set to 'production' for production deployment
FLASK_DEBUG=False  # Set to False in production

# Server Configuration
HOST=0.0.0.0
PORT=5000

# Google Gemini API (Required for AI-powered story generation)
# Get your API key from: https://makersuite.google.com/app/apikey
GOOGLE_API_KEY=your_google_api_key_here

# LLM Model Configuration (Optional)
# Model name must be from the allowed list (validated for security)
# Allowed models: gemini-2.5-flash, gemini-2.0-flash-exp, gemini-1.5-pro, gemini-1.5-flash, gemini-1.0-pro
# Default: gemini-2.5-flash
LLM_MODEL=gemini-2.5-flash

# LLM Temperature (Optional)
# Controls creativity: 0.0 = deterministic, 1.0 = very creative
# Default: 0.7
LLM_TEMPERATURE=0.7

# Redis Configuration (Optional, but recommended for production rate limiting)
# If not set, rate limiting will use in-memory storage (not suitable for multiple workers)
# Format: redis://localhost:6379/0 or redis://user:password@host:port/db
REDIS_URL=memory://

# Storage Configuration
# Use database storage (SQLite) instead of in-memory storage (recommended for production)
# Set to 'false' to use legacy in-memory storage (not recommended)
USE_DB_STORAGE=true

# Enable Redis caching for frequently accessed stories (requires Redis)
# Set to 'true' to enable caching layer on top of database storage
USE_REDIS_CACHE=false

# Gunicorn Configuration (Production only)
# GUNICORN_BIND=0.0.0.0:5000
# GUNICORN_WORKERS=4
# GUNICORN_ACCESS_LOG=logs/access.log
# GUNICORN_ERROR_LOG=logs/error.log
# GUNICORN_LOG_LEVEL=info

# Security (Production)
# SECRET_KEY=your-secret-key-here  # Generate a secure random key for production

